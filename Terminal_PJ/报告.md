# 报告

摘要、背景介绍、方法、数据和数据处理、结果和分析、结论，以及必要的参考文献。

### 摘要



### 背景介绍

我们尝试通过分析20年的摩托车交通事故数据，来统计性地得到有关交通事故发生的一些原因和特征，有利于

### 方法

### 数据和数据处理

#### 数据库

本文使用的数据库为California Traffic Collision Data from SWITRS。源数据全州综合交通记录系统来自加州公路巡警局 (CHP)发布的交通事故详细信息，数据库作者出于对摩托车驾驶的风险性的研究兴趣，对源数据进行收集和整理，将源数据中的编码等映射为可读性更高的文本内容，并公开发布在kaggle网站中，以鼓励更多有关于摩托车事故的研究。数据库中包含了加利福利亚州从2001年1月1日至2020年12月中旬的所有交通事故事件的信息，主要包含三个部分，即事故发生的基本信息，事故参与者以及事故伤亡者信息，这三个部分的信息被分别保存在三个table中，如下所示：

- collisions：每行包含一个事故的基本信息，包含每个事故的编号，天气状况，事故发生的日期和时间，发生事故的地段信息和路况，发生事故的经纬度，伤亡人数及其他信息。

- parties：每行包含事故的一个参与方，如车辆司机、行人、骑摩托车的人和停放的车辆，包含事故车辆的制造商、年份，参与方的年龄、性别、种族等等。

- victims：每行包含事故的一个事故伤亡者，该表中详细记录了parties中参与方的每一个伤亡者的基本信息，包括受伤程度、性别、年龄，以及伤亡者的车内位置和安全防护程度等等。

table之间的关系如下图的示例，一个事故对应不定数量的参与方，每个参与方包含不定数量的事故伤亡者。

![img](https://tims.berkeley.edu/help/images/SWITRS/database5.png)

#### 数据处理

##### 数据读取和预处理

数据库提供的原始文件为switrs.sqlite文件，是 SQLite 数据库文件，提供了一种轻量级、自包含的、无服务器的、多种系统兼容的数据库。为了便于进行摩托车数据的分析，使用`sqlite3`库进行读取，我们仅读取数据库中有摩托车参与的事故（即`motorcycle_collision == 1`的行），用游标来暂存SQL语句的执行结果，并保存为*.csv文件，以方便后续数据处理时，直接从csv文件中进行读取和保存。

```python
import pandas as pd
import sqlite3

# Connect to SQLite database
filename = './traffic_data/switrs.sqlite'   # # table: case_ids\collisions\victims\parties
conn = sqlite3.connect(filename)

# Create a cursor object 游标
cursor = conn.cursor()

# 只选取摩托车交通事故中的参与方
parties_query = " SELECT * FROM parties WHERE case_id IN \
(SELECT case_id FROM collisions WHERE motorcycle_collision == 1)"

# 只选取摩托车交通事故中的受害人
victims_query = " SELECT * FROM victims WHERE case_id IN \
(SELECT case_id FROM collisions WHERE motorcycle_collision == 1)"

# 只选取摩托车交通事故
collisions_query = "SELECT * FROM collisions WHERE motorcycle_collision == 1"

# Read the data
collisions = pd.read_sql_query(collisions_query, conn)
parties = pd.read_sql_query(parties_query, conn)
victims = pd.read_sql_query(victims_query, conn)

# 将选取的摩托车事故信息保存为csv，便于后续读取
filepath = './traffic_data/'
collisions.to_csv(filepath + 'collisions.csv', index=False)
parties.to_csv(filepath + 'parties.csv', index=False)
victims.to_csv(filepath + 'victims.csv', index=False)

# Close the connection
conn.close()
```

使用pandas对数据进行清洗。数据中有许多选填的数据项，为尽可能保留可分析的数据，在初始清洗时仅删除全为空的行。

```python
filepath = './traffic_data/'
collisions = pd.read_csv(filepath + 'collisions.csv')
collisions.dropna(how='all', inplace=True)  # 清除全为空的行
```

##### 位置信息

对table `collisions`中每个事故发生位置的经纬度信息进行分析，`latitude`和`longitude`列分别指明事故发生的经纬度。处理时，首先进行数据清洗，删除latitude和longitude列中含有空值的行，绘制出摩托车事故发生点的地图。由地图可以直观看出在整个加利福利亚州的交通事故频发地段。为了便于后续分析，可视化时同时绘制了加利福尼亚州的大城市位置信息。

```python
def location_statistics():
    position = collisions.copy()
    # 数据清洗
    # 删除latitude和longitude列中含有空值的行
    position.dropna(subset=['latitude', 'longitude'], inplace=True)

    # 加利福尼亚州大城市的经纬度位置
    cities = {
        'Los Angeles': (-118.2437, 34.0522),
        'San Diego': (-117.1611, 32.7157),
        'San Jose': (-121.8863, 37.3382),
        'San Francisco': (-122.4194, 37.7749),
        'Fresno': (-119.7871, 36.7378),
        'Sacramento': (-121.4944, 38.5816)
    }

    # 可视化
    fig, ax = plt.subplots()
    ax.scatter(position['longitude'], position['latitude'], s=3)
    for city, (lon, lat) in cities.items():
        ax.scatter(lon, lat, color='black', zorder=5)
        ax.text(lon, lat+0.2, city, color='black', fontsize=12, ha='center', va='center')

    # 设置标签
    ax.set_xlabel('Longitude')
    ax.set_ylabel('Latitude')
    ax.set_title('Collision Positions')
    plt.show()
```

##### 时间信息

对table `collisions`中每个事故发生的时间进行统计。`collision_date`指明了事故发生的日期，形式为YYYYMMDD。使用pandas进行日期格式转换，并在table `collisions`中增加一列`Year`，用于记录事故发生的年份，根据`Year`进行分类并统计各类的数量，绘制折线图，按照时间可视化显示各年份的事故数量。`collision_time`指明了事故发生的时间，形式为HH:MM:SS，也进行类似操作，提取小时并根据小时分组统计，按照时间可视化显示24小时制下每个小时的事故数量。

```python
def time_statistics():
    time_collision = collisions.copy()
    time_collision.dropna(subset=['collision_date', 'collision_time'], inplace=True)
    # 将COLLISION_DATE转换为日期格式，并提取年份
    # print(time_collision['collision_date'][0])
    time_collision['collision_date'] = pd.to_datetime(time_collision['collision_date'])
    time_collision['Year'] = time_collision['collision_date'].dt.year

    # 将COLLISION_TIME转换为时间格式，并提取小时
    time_collision['collision_time'] = pd.to_datetime(time_collision['collision_time'], format='%H:%M:%S').dt.hour

    # 按年份分组并统计数量
    yearly_counts = time_collision.groupby('Year').size()
    print(yearly_counts)
    # 按小时分组并统计数量
    hourly_counts = time_collision.groupby('collision_time').size()

    # 可视化
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))
    # 年份统计
    yearly_counts.plot(kind='line', ax=axes[0])
    axes[0].scatter(yearly_counts.index, yearly_counts.values, marker='o', linestyle='-', c='g')
    axes[0].set_title('Number of Collisions by Year')
    axes[0].set_xlabel('Year')
    axes[0].set_ylabel('Number of Collisions')
    axes[0].xaxis.set_major_locator(MaxNLocator(integer=True))  # 控制横坐标间隔为整数

    # 24小时统计
    hourly_counts.plot(kind='line', ax=axes[1])
    axes[1].scatter(hourly_counts.index, hourly_counts.values, marker='o', linestyle='-', c='g')
    axes[1].set_title('Number of Collisions by Hour of the Day')
    axes[1].set_xlabel('Hour of the Day')
    axes[1].set_ylabel('Number of Collisions')
    axes[1].set_xticks(range(0, 24))
    axes[1].set_xticks(np.arange(0, 24, 1))  # 控制小时间隔为1小时
    plt.tight_layout()
    plt.show()
```

##### 天气信息

对table `collisions`中每个事故发生的天气进行统计。`collisions`中与天气相关的列为`weather_1`，`weather_2`，绝大多数数据含有`weather_1`，仅有少数数据含有`weather_2`数据，因此使用(weather_1, weather_2)的形式来表示事故发生的天气，对于两列中出现的空值，使用'-'符号代替。统计每种天气组合下事故发生的数量，并可视化展示其中发生事故数量最高的10种天气组合。

```python
def weather_statistics():
    weather = collisions.copy()
    # 数据清洗
    # 替换其中空的数据为-，每个事故信息含[0,2]个天气信息
    weather[['weather_1', 'weather_2']] = weather[['weather_1', 'weather_2']].replace(np.nan, '-')
    # 按(weather1,weather2)分组并统计数量
    weather_counts = weather.groupby(['weather_1', 'weather_2']).size()
    # print(weather_counts)
    weather_condition_type = weather_counts[0:10].index.tolist()
    weather_condition = weather_counts.nlargest(10)
    # print(weather_condition)

    # 可视化
    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))
    # 年份统计
    weather_condition.plot(kind='bar')
    axes.set_title('Number of Collisions in Weathers')
    axes.set_xlabel('Weather')
    axes.set_ylabel('Number of Collisions')
    # 在每个柱上显示数据
    for i, value in enumerate(weather_condition):
        axes.text(i, value, str(value), ha='center', va='bottom')
    axes.set_xticklabels(weather_condition.index, rotation=30)
    plt.show()
```

##### 事故严重程度预测

在table `collisions`中，根据各种事故中的因素预测事故的严重程度。本文根据伤亡人数来划分事件的严重程度，新增fatal列来表示。若死亡人数大于0或伤者人数大于3时，认为事故严重，fatal为1，其他情况认为事故较轻微，fatal为0。预测使用的特征及其含义如下表。训练模型选择逻辑回归，训练和测试时，训练集与测试集比例为4: 1。

| 列名                 | 含义                                                         |
| -------------------- | ------------------------------------------------------------ |
| alcohol_involved     | 事故参与方（不计乘客）是否饮酒                               |
| road_surface         | 路况，如wet，dry，snowy等                                    |
| lighting             | 照明情况                                                     |
| control_device       | 与事故相关的交通控制设备的存在和状况，如监管、警告和施工标志等 |
| pedestrian_collision | 事故是否涉及行人                                             |
| bicycle_collision    | 事故是否涉及自行车                                           |
| motorcycle_collision | 事故是否涉及摩托车                                           |
| truck_collision      | 事故是否涉及货车                                             |

```python
def predict_severity():
    severity = collisions.copy()
    # severity.dropna(subset=['killed_victims'], inplace=True)
    severity['killed_victims'].fillna(0, inplace=True)
    severity['alcohol_involved'].fillna(0, inplace=True)
    severity['fatal'] = np.where((severity['killed_victims'] > 0) | (severity['injured_victims'] > 3), 1, 0)

    target = 'fatal'
    features = ['alcohol_involved', 'road_surface', 'lighting', 'control_device',
                'pedestrian_collision', 'bicycle_collision', 'motorcycle_collision', 'truck_collision']
    one_hot_encoder = OneHotEncoder()
    preprocessor = ColumnTransformer(
        transformers=[
            ('onehot', one_hot_encoder, features)
        ],
        remainder='passthrough'
    )

    # 创建逻辑回归模型
    model = LogisticRegression()
    pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                               ('model', model)])
    X = severity[features]
    y = severity[target].apply(lambda x: 1 if x > 0 else 0)  # 转换为二元标签

    # 训练
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)
    pipeline.fit(X_train, y_train)
    predictions = pipeline.predict(X_test)

    print(classification_report(y_test, predictions))
```



##### 事故车辆制造商统计

对table `parties`中每个事故的车辆制造商进行统计。

```python
def motorcycle_type_statistics():
    motorcycle_type = parties.copy()
    # 数据清洗
    motorcycle_type.dropna(subset=['vehicle_make'], inplace=True)
    # 统计数量
    motorcycle_type_counts = motorcycle_type.groupby(['vehicle_make']).size()
    motorcycle_type_counts_top = motorcycle_type_counts.nlargest(10)

    # 可视化
    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))
    # 年份统计
    motorcycle_type_counts_top.plot(kind='bar')
    axes.set_title('Number of Motorcycle_type in Collision')
    axes.set_xlabel('Motorcycle_type')
    axes.set_ylabel('Number of Motorcycle_type')
    # 在每个柱上显示数据
    for i, value in enumerate(motorcycle_type_counts_top):
        axes.text(i, value, str(value), ha='center', va='bottom')
    axes.set_xticklabels(motorcycle_type_counts_top.index, rotation=30)
    plt.show()

```

##### 伤亡者位置统计

对table `victims`中每个伤亡者在车辆中所处的位置进行统计。`victim_seating_position`表明了伤亡者在车辆中乘坐的座位，如司机、普通汽车的各个乘客座位、卡车、巴士座位等等，由此可以直观得到各个位置在事故发生时的风险程度。

```python
def victim_position():
    victim_pos = victims.copy()
    # 数据清洗
    # 删除victim_seating_position列中含有空值的行
    victim_pos.dropna(subset=['victim_seating_position'], inplace=True)
    victim_pos_counts = victim_pos.groupby(['victim_seating_position']).size()
    victim_pos_counts = victim_pos_counts.sort_values(ascending=False)
    # 可视化
    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))
    # 年份统计
    victim_pos_counts.plot(kind='bar')
    axes.set_title('Number of Victims in Seating Positions')
    axes.set_xlabel('Victim Seating Position')
    axes.set_ylabel('Number of Victims')
    # 在每个柱上显示数据
    for i, value in enumerate(victim_pos_counts):
        axes.text(i, value, str(value), ha='center', va='bottom')
    axes.set_xticklabels(victim_pos_counts.index, rotation=20)
    plt.show()
```

##### 伤亡者受伤程度和各种因素之间的相关性

对table `victims`中每个伤亡者受伤程度与其他因素之间的相关性进行分析。`victim_degree_of_injury`指明了伤亡者受伤程度，`victim_role`指明了伤亡者的身份（如行人、司机、乘客等），`victim_sex`和`victim_age`指明伤亡者的性别和年龄，`victim_seating_position`指明了伤亡者在车辆上的位置（如司机、后排、未知等），`victim_safety_equipment_1`和`victim_safety_equipment_1`指明了伤亡者的安全措施情况（如是否使用安全带、是否使用儿童座椅、是否弹出安全气囊等）。

实验时分别检验了这些列两两之间的关系，尤其关注victim_degree_of_injury与其他因素之间的关联程度。本文中主要使用协方差和卡方检验的方法来验证因素之间的相关性。

```python
def factors2injury_degree():
    injury_factors = victims.copy()
    # 数据清洗
    factor = ['victim_degree_of_injury', 'victim_role', 'victim_sex',
              'victim_age', 'victim_seating_position',
              'victim_safety_equipment_1', 'victim_safety_equipment_2',
              'victim_ejected']
    injury_factors.dropna(subset=factor, inplace=True)
    # 这里假设这些列是分类数据
    for column in factor:
        injury_factors[column] = injury_factors[column].astype('category').cat.codes

    # 计算相关性
    correlation_matrix_full = injury_factors[factor].corr()  # -1到1之间，其中1表示完全正相关，-1表示完全负相关，0表示没有相关性
    correlation_matrix = correlation_matrix_full[['victim_degree_of_injury']].sort_values(
        by='victim_degree_of_injury', ascending=False)

    # 可视化
    plt.figure(figsize=(8, 8))
    # sns.heatmap(correlation_matrix_full, annot=True, cmap='coolwarm')
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
    plt.title('Correlation Analysis')
    plt.xticks(rotation=0)
    plt.yticks(rotation=20)
    plt.show()

    # 卡方检验
    # 创建列联表
    for column in factor:
        contingency_table = pd.crosstab(injury_factors[column][0:10000],
                                        injury_factors['victim_degree_of_injury'][0:10000])
        # 执行卡方检验
        chi2, p, dof, expected = chi2_contingency(contingency_table)

        # 输出卡方检验的结果
        print("Chi2 Statistic:", chi2)
        print("P-value:", p)
```



### 结果和分析

地理位置信息

事故主要集中在几个大型城市，如图片右下角的洛杉矶、图片左上方的旧金山和萨克拉门托等地。

![Figure_location_statistics1](.\result\Figure_location_statistics1.png)

时间信息

按照年份，事故次数从2001年起基本处于波动上升的状态，并在2016年到达峰值，此后开始下降。2019年-2020年的急剧下降可能受到Covid-19的影响，疫情的冲击减少了交通出行的频率，由此导致了事故发生次数的下降。

按照24小时制，事故发生次数最少在3-4点，该时间段为休息时段，车辆较少，事故发生次数最多在15-18时，在傍晚时分受到日落光照和晚高峰车流量的影响而事故数量最多。在早上7点出现了一个小峰值，

![](.\result\Figure_time_statistics1.png)

天气信息

晴朗天气下

加州整体为温带气候，冬季多雨湿润，平均气温7℃-17℃；夏季干燥，阳光充足，平均气温15℃-26℃。 全州气候条件多样，南部沙漠地区较干旱，北部沿海冬季雨雪较多

![](.\result\Figure_weather1.png)

事故车辆制造商统计



![](.\result\Figure_motorcycle_type1.png)

伤亡者位置统计

加利福尼亚州车辆靠右行驶，即驾驶位位于整车的前排左方。座位的编号和布局如图1所示，https://www.nhtsa.gov/sites/nhtsa.gov/files/documents/ca_chp555_manual_2_2003_ch1-13.pdf。

![1704287210445](.\img\seating_position.png)

最多的是司机，这部分是由于

- Driver's Seat (1), Front Passenger Seat (2)
- **Second Row**: Left Rear Passenger Seat (3), Center Rear Passenger Seat (4), Right Rear Passenger Seat (5)【

![](D:\code_python\Data_assignment\Terminal_PJ\result\Figure_victim_position1.png)

### 结论

### 参考文献





